{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494e6204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 9971 images belonging to 6 classes.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "312/312 [==============================] - 621s 2s/step - loss: 0.8806 - accuracy: 0.6665\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 588s 2s/step - loss: 0.6207 - accuracy: 0.7753\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 586s 2s/step - loss: 0.5296 - accuracy: 0.8057\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 577s 2s/step - loss: 0.4418 - accuracy: 0.8384\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 583s 2s/step - loss: 0.4152 - accuracy: 0.8486\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 579s 2s/step - loss: 0.3861 - accuracy: 0.8611\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 580s 2s/step - loss: 0.3368 - accuracy: 0.8822\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - 580s 2s/step - loss: 0.3240 - accuracy: 0.8828\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - 578s 2s/step - loss: 0.3013 - accuracy: 0.8936\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - 582s 2s/step - loss: 0.2829 - accuracy: 0.8997\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - 582s 2s/step - loss: 0.2703 - accuracy: 0.9080\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - 581s 2s/step - loss: 0.2473 - accuracy: 0.9152\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - 581s 2s/step - loss: 0.2661 - accuracy: 0.9094\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - 579s 2s/step - loss: 0.2279 - accuracy: 0.9212\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - 580s 2s/step - loss: 0.2193 - accuracy: 0.9238\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - 581s 2s/step - loss: 0.2087 - accuracy: 0.9275\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - 580s 2s/step - loss: 0.2007 - accuracy: 0.9290\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - 582s 2s/step - loss: 0.1948 - accuracy: 0.9329\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - 580s 2s/step - loss: 0.1854 - accuracy: 0.9344\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - 578s 2s/step - loss: 0.1711 - accuracy: 0.9416\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - 579s 2s/step - loss: 0.1670 - accuracy: 0.9431\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - 323s 1s/step - loss: 0.1635 - accuracy: 0.9422\n",
      "Epoch 23/50\n",
      "312/312 [==============================] - 242s 775ms/step - loss: 0.1572 - accuracy: 0.9428\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - 243s 777ms/step - loss: 0.1463 - accuracy: 0.9485\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - 242s 774ms/step - loss: 0.1377 - accuracy: 0.9514\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - 243s 778ms/step - loss: 0.1323 - accuracy: 0.9535\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - 243s 778ms/step - loss: 0.1297 - accuracy: 0.9539\n",
      "Epoch 28/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.1192 - accuracy: 0.9606\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - 242s 776ms/step - loss: 0.1157 - accuracy: 0.9612\n",
      "Epoch 30/50\n",
      "312/312 [==============================] - 242s 774ms/step - loss: 0.1128 - accuracy: 0.9604\n",
      "Epoch 31/50\n",
      "312/312 [==============================] - 242s 775ms/step - loss: 0.1068 - accuracy: 0.9620\n",
      "Epoch 32/50\n",
      "312/312 [==============================] - 242s 775ms/step - loss: 0.1045 - accuracy: 0.9649\n",
      "Epoch 33/50\n",
      "312/312 [==============================] - 242s 776ms/step - loss: 0.1104 - accuracy: 0.9599\n",
      "Epoch 34/50\n",
      "312/312 [==============================] - 242s 776ms/step - loss: 0.0954 - accuracy: 0.9671\n",
      "Epoch 35/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.1220 - accuracy: 0.9578\n",
      "Epoch 36/50\n",
      "312/312 [==============================] - 243s 778ms/step - loss: 0.1065 - accuracy: 0.9628\n",
      "Epoch 37/50\n",
      "312/312 [==============================] - 244s 782ms/step - loss: 0.0924 - accuracy: 0.9689\n",
      "Epoch 38/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.0929 - accuracy: 0.9683\n",
      "Epoch 39/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.0838 - accuracy: 0.9725\n",
      "Epoch 40/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.0824 - accuracy: 0.9713\n",
      "Epoch 41/50\n",
      "312/312 [==============================] - 244s 780ms/step - loss: 0.0878 - accuracy: 0.9687\n",
      "Epoch 42/50\n",
      "312/312 [==============================] - 244s 782ms/step - loss: 0.0805 - accuracy: 0.9724\n",
      "Epoch 43/50\n",
      "312/312 [==============================] - 244s 781ms/step - loss: 0.0773 - accuracy: 0.9735\n",
      "Epoch 44/50\n",
      "312/312 [==============================] - 243s 779ms/step - loss: 0.0733 - accuracy: 0.9763\n",
      "Epoch 45/50\n",
      "312/312 [==============================] - 245s 784ms/step - loss: 0.0733 - accuracy: 0.9745\n",
      "Epoch 46/50\n",
      "312/312 [==============================] - 243s 778ms/step - loss: 0.0715 - accuracy: 0.9754\n",
      "Epoch 47/50\n",
      "312/312 [==============================] - 242s 776ms/step - loss: 0.0669 - accuracy: 0.9761\n",
      "Epoch 48/50\n",
      "312/312 [==============================] - 242s 774ms/step - loss: 0.0657 - accuracy: 0.9774\n",
      "Epoch 49/50\n",
      "312/312 [==============================] - 246s 786ms/step - loss: 0.0647 - accuracy: 0.9790\n",
      "Epoch 50/50\n",
      "312/312 [==============================] - 244s 782ms/step - loss: 0.0585 - accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to your dataset\n",
    "train_data_dir = r\"D:\\P_126\\Dataset_new\\train-20230326T152931Z-001\\train\"\n",
    "\n",
    "# Specify image dimensions and batch size\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Extract class names from the folder names\n",
    "class_names = sorted(os.listdir(train_data_dir))\n",
    "\n",
    "# Create data generator for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')  # Use 'sparse' for integer labels\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "cnn_input = Input(shape=(img_width, img_height, 3))\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten()\n",
    "])\n",
    "cnn_output = cnn_model(cnn_input)\n",
    "cnn_output_reshaped = tf.reshape(cnn_output, (-1, 1, cnn_output.shape[1]))  # Reshape for LSTM\n",
    "\n",
    "# Define the LSTM model for sequence modeling\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, input_shape=(1, cnn_output.shape[1])),\n",
    "    Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "lstm_output = lstm_model(cnn_output_reshaped)\n",
    "\n",
    "# Combine the CNN and LSTM models\n",
    "combined_model = Model(inputs=cnn_input, outputs=lstm_output)\n",
    "\n",
    "# Compile and train the model\n",
    "combined_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "combined_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50)\n",
    "# Save the trained model\n",
    "combined_model.save('lung_detection_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7a58be-0504-40f7-a278-978e3275960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1966 images belonging to 6 classes.\n",
      "62/62 [==============================] - 21s 339ms/step - loss: 0.4007 - accuracy: 0.8957\n",
      "Test loss: 0.4006696343421936\n",
      "Test accuracy: 0.8957273364067078\n",
      "62/62 [==============================] - 21s 339ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set the path to your test dataset\n",
    "test_data_dir = r\"D:\\P_126\\Dataset_new\\test-20230326T155708Z-001\\test\"\n",
    "\n",
    "# Create data generator for test data (no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # Use 'sparse' for integer labels\n",
    "    shuffle=False)  # Disable shuffling to maintain the order of images\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = combined_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "# Optionally, make predictions on the test data\n",
    "predictions = combined_model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8564f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 586ms/step\n",
      "Predicted class: NORMAL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'lung_detection_cnnlstm.h5'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Define your custom class names\n",
    "class_names = ['CARDIOMEGALY', 'COVID', 'NORMAL', 'PNEUMONIA', 'PNEUMOTHORAX', 'TUBERCULOSIS']\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = r\"C:\\Users\\Administrator\\Desktop\\00000403_001.png\"\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "# img_array = np.expand_dims(img_array, axis=1)  # Remove this line\n",
    " # Add a batch dimension\n",
    " # Add a time dimension\n",
    "img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction\n",
    "predictions = loaded_model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get the predicted class name from the custom class names list\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "# Display the predicted class\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9971 images belonging to 6 classes.\n",
      "Epoch 1/30\n",
      "312/312 [==============================] - 480s 1s/step - loss: 0.9238 - accuracy: 0.6522\n",
      "Epoch 2/30\n",
      "312/312 [==============================] - 341s 1s/step - loss: 0.6136 - accuracy: 0.7760\n",
      "Epoch 3/30\n",
      "312/312 [==============================] - 486s 2s/step - loss: 0.5332 - accuracy: 0.8035\n",
      "Epoch 4/30\n",
      "312/312 [==============================] - 685s 2s/step - loss: 0.5001 - accuracy: 0.8208\n",
      "Epoch 5/30\n",
      "182/312 [================>.............] - ETA: 4:15 - loss: 0.4370 - accuracy: 0.8474"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to your dataset\n",
    "train_data_dir = r\"D:\\P_126\\Dataset_new\\train-20230326T152931Z-001\\train\"\n",
    "\n",
    "# Specify image dimensions and batch size\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Extract class names from the folder names\n",
    "class_names = sorted(os.listdir(train_data_dir))\n",
    "\n",
    "# Create data generator for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')  # Use 'sparse' for integer labels\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "cnn_input = Input(shape=(img_width, img_height, 3))\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten()\n",
    "])\n",
    "cnn_output = cnn_model(cnn_input)\n",
    "cnn_output_reshaped = tf.reshape(cnn_output, (-1, 1, cnn_output.shape[1]))  # Reshape for LSTM\n",
    "\n",
    "# Define the LSTM model for sequence modeling\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, input_shape=(1, cnn_output.shape[1])),\n",
    "    Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "lstm_output = lstm_model(cnn_output_reshaped)\n",
    "\n",
    "# Combine the CNN and LSTM models\n",
    "combined_model = Model(inputs=cnn_input, outputs=lstm_output)\n",
    "\n",
    "# Compile and train the model\n",
    "combined_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "combined_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=30)\n",
    "# Save the trained model\n",
    "combined_model.save('lung_detection_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your test dataset\n",
    "test_data_dir = r\"D:\\P_126\\Dataset_new\\test-20230326T155708Z-001\\test\"\n",
    "\n",
    "# Create data generator for test data (no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # Use 'sparse' for integer labels\n",
    "    shuffle=False)  # Disable shuffling to maintain the order of images\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = combined_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "# Optionally, make predictions on the test data\n",
    "predictions = combined_model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'lung_detection_cnnlstm.h5'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Define your custom class names\n",
    "class_names = ['CARDIOMEGALY', 'COVID', 'NORMAL', 'PNEUMONIA', 'PNEUMOTHORAX', 'TUBERCULOSIS']\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = r\"C:\\Users\\Administrator\\Desktop\\00000403_001.png\"\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "# img_array = np.expand_dims(img_array, axis=1)  # Remove this line\n",
    " # Add a batch dimension\n",
    " # Add a time dimension\n",
    "img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction\n",
    "predictions = loaded_model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get the predicted class name from the custom class names list\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "# Display the predicted class\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert predicted probabilities into class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels from the test generator\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Compute precision, recall, and the confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
