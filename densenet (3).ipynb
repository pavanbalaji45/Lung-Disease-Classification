{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5267d9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 9971 images belonging to 6 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\asuto\\AppData\\Local\\Temp\\ipykernel_21284\\2278482411.py\", line 34, in <module>\n",
      "    inception_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=cnn_input)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\inception_v3.py\", line 299, in InceptionV3\n",
      "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\inception_v3.py\", line 433, in conv2d_bn\n",
      "    x = layers.Conv2D(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py\", line 2100, in random_uniform\n",
      "    return tf.random.stateless_uniform(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[1,7,192,192] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:AddV2] name: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
      "    self.tree = ast.parse(self.text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asuto\\anaconda3.o\\Lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Input, Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, InceptionV3\n",
    "\n",
    "# Set the path to your dataset\n",
    "train_data_dir = r\"C:\\Users\\asuto\\Desktop\\intern ship 2\\lung detection\\archive\\archive\\train-20230326T152931Z-001\\train\"\n",
    "\n",
    "# Specify image dimensions and batch size\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Extract class names from the folder names\n",
    "class_names = sorted(os.listdir(train_data_dir))\n",
    "\n",
    "# Create data generator for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')  # Use 'sparse' for integer labels\n",
    "\n",
    "# Define the InceptionV3 model for feature extraction\n",
    "cnn_input = Input(shape=(img_width, img_height, 3))\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=cnn_input)\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output of the InceptionV3 model\n",
    "inception_output = inception_model.output\n",
    "\n",
    "# Flatten the output\n",
    "flatten_layer = Flatten()(inception_output)\n",
    "\n",
    "# Define the DenseNet121 model for feature extraction\n",
    "densenet_input = Input(shape=(img_width, img_height, 3))\n",
    "densenet_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=densenet_input)\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in densenet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output of the DenseNet121 model\n",
    "densenet_output = densenet_model.output\n",
    "\n",
    "# Concatenate the outputs of InceptionV3 and DenseNet121\n",
    "concatenated_output = Concatenate()([flatten_layer, densenet_output])\n",
    "\n",
    "# Define the LSTM model for sequence modeling\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, input_shape=(1, concatenated_output.shape[1])),\n",
    "    Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "lstm_output = lstm_model(tf.expand_dims(concatenated_output, axis=1))\n",
    "\n",
    "# Combine the InceptionV3, DenseNet121, and LSTM models\n",
    "combined_model = Model(inputs=[cnn_input, densenet_input], outputs=lstm_output)\n",
    "\n",
    "# Compile and train the model\n",
    "combined_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "combined_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=2)\n",
    "\n",
    "# Save the trained model\n",
    "combined_model.save('lung_detection_inceptionv3_densenet121.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98220a52-8dce-4231-8bc1-adb67b5c8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your test dataset\n",
    "test_data_dir = r\"C:\\Users\\asuto\\Desktop\\intern ship 2\\lung detection\\archive\\archive\\test-20230326T155708Z-001\\test\"\n",
    "\n",
    "# Create data generator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')  # Use 'sparse' for integer labels\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = combined_model.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(test_generator))\n",
    "\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bae735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 423ms/step\n",
      "Predicted class: COVID\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'lung_detection_dblstm.h5'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Define your custom class names\n",
    "class_names = ['CARDIOMEGALY', 'COVID', 'NORMAL', 'PNEUMONIA', 'PNEUMOTHORAX', 'TUBERCULOSIS']\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = r\"C:\\Users\\asuto\\Desktop\\intern ship 2\\lung detection\\archive\\test-20230326T155708Z-001\\test\\COVID\\COVID-19 (8).jpeg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=1)  # Add a time dimension\n",
    "img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction\n",
    "predictions = loaded_model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get the predicted class name from the custom class names list\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "# Display the predicted class\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58336023-c411-49f9-ae46-bd3e72e22ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
